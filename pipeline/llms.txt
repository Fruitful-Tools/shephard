# Shepard Pipeline

> A Prefect-powered AI transcription and summarization system that transforms YouTube videos, audio files, and text content into structured insights through configurable AI workflows. **This llms.txt file is the preferred entry point for understanding the project structure.**

## Core Architecture

The pipeline supports three entry points: YouTube videos (yt-dlp download with time ranges → extract audio → transcribe → summarize), audio file uploads (chunk → transcribe → correct → summarize), and text transcripts (direct summarization). Built with Python 3.12, Prefect 3.0+ for orchestration, and Pydantic for type safety.

Key components:
- **Modular Prefect Tasks**: Each processing step (download, transcription, correction, summarization) is an independent, retryable task
- **Runtime Configuration**: Model selection, chunk sizes, time ranges, and AI instructions configurable per job
- **Mock-First Development**: All external APIs (YouTube, Voxtral, OpenAI, Supabase) mocked for local development with seamless production toggle
- **YouTube Integration**: Real yt-dlp implementation with precise time range extraction and production-grade audio processing
- **Type-Safe Workflows**: Full type validation with comprehensive Pydantic schemas

## Project Files

- [shepard_pipeline/flows/main_flows.py](shepard_pipeline/flows/main_flows.py): Core Prefect flow definitions for all three entry points
- [shepard_pipeline/models/pipeline.py](shepard_pipeline/models/pipeline.py): Pydantic data models for inputs, outputs, and processing results
- [shepard_pipeline/services/mock_apis.py](shepard_pipeline/services/mock_apis.py): Mock implementations of all external AI services
- [shepard_pipeline/services/youtube_service.py](shepard_pipeline/services/youtube_service.py): Real YouTube download service using yt-dlp with time range support
- [shepard_pipeline/tasks/](shepard_pipeline/tasks/): Individual Prefect tasks for audio processing, transcription, and summarization
- [shepard_pipeline/config/settings.py](shepard_pipeline/config/settings.py): Environment-based configuration management
- [shepard_pipeline/cli/main.py](shepard_pipeline/cli/main.py): Command-line interface with rich terminal output
- [shepard_pipeline/demo.py](shepard_pipeline/demo.py): Interactive demonstration of all pipeline capabilities

## Development Setup

- [pyproject.toml](pyproject.toml): Modern Python project configuration with uv dependency management
- [docker-compose.yml](docker-compose.yml): Local development infrastructure (Prefect server, PostgreSQL, worker)
- [.env.example](.env.example): Environment configuration template with mock service settings
- [.pre-commit-config.yaml](.pre-commit-config.yaml): Automated code quality hooks with Ruff, mypy, and typos

## Documentation

- [llm-docs/project-spec.md](llm-docs/project-spec.md): Architectural blueprint and deployment strategy
- [llm-docs/local-dev.md](llm-docs/local-dev.md): Comprehensive development environment setup with pyenv and uv
- [llm-docs/code-quality.md](llm-docs/code-quality.md): Modern Python tooling standards and pre-commit workflow
- [llm-docs/logging.md](llm-docs/logging.md): Hybrid logging approach combining Prefect's get_run_logger with Loguru
- [llm-docs/youtube-integration.md](llm-docs/youtube-integration.md): Complete YouTube download implementation with yt-dlp and time range extraction

## Tests

- [tests/integration/test_flows.py](tests/integration/test_flows.py): End-to-end pipeline testing with Prefect test harness
- [tests/unit/](tests/unit/): Unit tests for models, services, and individual components
- [tests/conftest.py](tests/conftest.py): Pytest fixtures and mock service setup

## Development Workflow

**Context7 Integration**: Use Context7 (https://context7.com) to fetch latest best practices for our tech stack (Prefect 3.0+, uv, mypy, Ruff, pytest, Pydantic) when developing new features or fixing issues.

**Documentation Cycle**: When making changes, update or create documentation in llm-docs/ as needed, then update entries in this llms.txt file to complete the development cycle and maintain accurate project overview.

## Optional

Pipeline uses mock services by default for development. Real integrations include:
- **YouTube Downloads**: yt-dlp with time range extraction (`youtube_start_time`, `youtube_end_time`)
- **AI Services**: Voxtral for transcription, Mistral for text correction, OpenAI GPT-4 for summarization
- **Data Storage**: Supabase for job tracking
- **Interactive Demo**: Enhanced demo.py with API mode toggle and comprehensive testing capabilities

The system supports runtime model selection, custom AI instructions per job, and seamless switching between mock and production APIs via `MOCK_EXTERNAL_APIS` environment variable.
